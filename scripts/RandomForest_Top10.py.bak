import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from imblearn.over_sampling import SMOTE
from collections import Counter

# ğŸ“¥ Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
df = pd.read_csv('data/kino_features.csv')

# âœ… Î•Î½Î·Î¼ÎµÏÏ‰Î¼Î­Î½Î± top-10 features (Î¼ÏŒÎ½Î¿ Ï…Ï€Î¬ÏÏ‡Î¿Î½Ï„Î±)
top10_features = ['num_8', 'num_4', 'num_14', 'gap_1', 'gap_17', 'gap_43', 'num_12', 'num_5', 'freq_8', 'freq_4']

print("\nğŸ“Œ Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ½Ï„Î±Î¹ Ï„Î± Top-10 features:")
print(top10_features)

# ğŸ¯ Î£Ï„ÏŒÏ‡Î¿Ï‚
y = df['is_7_hit']
X = df[top10_features]

# ğŸ”„ SMOTE Î³Î¹Î± Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î¯Î±
print("\nğŸ” ÎšÎ±Ï„Î±Î½Î¿Î¼Î® 'is_7_hit':")
print(y.value_counts())

smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

print("\nğŸ” ÎÎ­Î± ÎºÎ±Ï„Î±Î½Î¿Î¼Î® Î¼ÎµÏ„Î¬ Ï„Î¿ SMOTE:")
print(Counter(y_resampled))

# âœ‚ï¸ Train/Test split
X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)

# ğŸŒ³ Random Forest
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# ğŸ“Š Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·
acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred)
rec = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f"\nğŸ¯ Accuracy: {acc:.2f}")
print(f"ğŸ“Œ Precision: {prec:.2f}")
print(f"ğŸ“ˆ Recall: {rec:.2f}")
print(f"ğŸ§ª F1-Score: {f1:.2f}")

# ğŸ” Cross-validation
scores = cross_val_score(model, X_resampled, y_resampled, cv=5)
print(f"\nâœ… Î‘Î¾Î¹Î¿Î»Î¿Î³Î®ÏƒÎµÎ¹Ï‚ Î¼Îµ Cross-Validation: {scores}")
print(f"ğŸ“Š ÎœÎ­ÏƒÎ· Î±ÎºÏÎ¯Î²ÎµÎ¹Î±: {scores.mean():.4f}")

